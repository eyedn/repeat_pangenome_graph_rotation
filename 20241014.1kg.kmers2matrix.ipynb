{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6377ad",
   "metadata": {},
   "source": [
    "- This notebook demonstrates how to convert kmer genotype matrix to motif genotype matrix\n",
    "    - In the previous preprocessing step, I computed the correspondence from kmer to motif.\n",
    "      So once I have a kmer matrix, where each row is a kmer and each col is a sample,\n",
    "      I can simply do row operations to get the motif dosage.\n",
    "    - It takes about 10 min to compute each batch of data in `compute_gt_cgt_batch`.\n",
    "      You could speed it up by moving the code to a Python script and using SLURM's array job.\n",
    "      Just optional. \n",
    "    - Watch out for memory usage and remmeber to allocate enough mem for your compute node,\n",
    "      otherwise ipython kernel would die\n",
    "- With motif genotype matrix, we can then perform LD pruning over motifs\n",
    "    - Add another function to save in tsv.gz format instead of pikcle for portability\n",
    "    - Use PLINK or write your own code given certain LD threshold\n",
    "- Data structure in this notebook that can be useful for LD pruning\n",
    "    - `ccki_tr`: cumulative number of canonical compressed kmer (cck) per TR locus\n",
    "        - cck is equivalent to motif in our definition\n",
    "        - vector of size NTR (Number of TR loci)\n",
    "        - retrieve # of cck in each locus `i` by\n",
    "            - `ccki_tr[i] -  ccki_tr[i-1]` if i > 0\n",
    "            - `ccki_tr[i]` if i == 0\n",
    "        - we will need this to perform LD pruning for each locus, or a block in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "srcdir = \"/project/mchaisso_100/cmb-16/tsungyul/work/vntr/danbing-tk/script/\"\n",
    "sys.path.insert(0, srcdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c9faed-6d10-451b-b8fb-ee67737cbae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vntrutils as vu\n",
    "import utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import itertools\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import gzip\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "matplotlib.rc('font', size=7)\n",
    "matplotlib.rc('axes', titlesize=7)\n",
    "matplotlib.rc('xtick', labelsize=5)\n",
    "matplotlib.rc('ytick', labelsize=5)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ffe4bf-9047-4c6a-9f30-34a727d89596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        ki_tr, ccki_tr = pickle.load(f)\n",
    "    return ki_tr, ccki_tr\n",
    "\n",
    "def get_2(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        ks, ccks, tr_cck_ns, ki_map = pickle.load(f)\n",
    "    tr_cck_ns = np.array(tr_cck_ns)\n",
    "    return ks, ccks, tr_cck_ns, ki_map\n",
    "\n",
    "def gather_motifs(gt_HPRC, NCCK, NB, out_dir):\n",
    "    genomes = np.loadtxt(gt_HPRC, dtype=object)\n",
    "    ng = genomes.size\n",
    "    BS = ng//NB\n",
    "    \n",
    "    print(f\"Loading batches...\")\n",
    "    print(BS, ng, NB)\n",
    "    sys.stdout.flush()\n",
    "    cgt = np.zeros([NCCK,ng], dtype=np.float32)\n",
    "    for i in range(NB):\n",
    "        print(f\"Loading batch {i+1}\")\n",
    "        sys.stdout.flush()\n",
    "        BS_ = BS if i != NB-1 else ng - BS*i\n",
    "        si = i*BS\n",
    "        ei = i*BS + BS_\n",
    "        with open(f\"{out_dir}/cgt.{i}.pickle\", 'rb') as f:\n",
    "            cgt[:,si:ei] = pickle.load(f)\n",
    "    print(\"Dumping cgt...\")\n",
    "    sys.stdout.flush()\n",
    "    with open(f\"{out_dir}/cgt.pickle\", 'wb') as f:\n",
    "        pickle.dump(cgt, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return cgt\n",
    "\n",
    "def adjust_coverage(cgt, gt_HPRC, HPRC_chr1_cov, out_dir):\n",
    "    print(\"Loading coverage...\")\n",
    "    sys.stdout.flush()\n",
    "    genomes = np.loadtxt(gt_HPRC, dtype=object)\n",
    "    cov = np.array([float(c) for g, c in np.loadtxt(HPRC_chr1_cov, dtype=object) if g in genomes])\n",
    "    print(\"Computing acgt...\")\n",
    "    sys.stdout.flush()\n",
    "    cgt /= cov\n",
    "    print(\"Dumping acgt...\")\n",
    "    sys.stdout.flush()\n",
    "    with open(f\"{out_dir}/acgt.pickle\", 'wb') as f:\n",
    "        pickle.dump(cgt, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return cgt\n",
    "\n",
    "def compute_partial_ld_r2(acgt, ccki_tr, ccks, r2_threshold, out_dir, start_idx, end_idx):\n",
    "    # keep track of which variants have been pruned\n",
    "    init_locus_start = ccki_tr[start_idx] if start_idx != 0 else 0\n",
    "    pruned_size = ccki_tr[end_idx] - init_locus_start\n",
    "    pruned = np.zeros(pruned_size, dtype=bool)\n",
    "    print(f\"Pruning loci from {start_idx} to {end_idx}...\")\n",
    "    print(f\"r^2 threshold = {r2_threshold}\")\n",
    "    print(f\"loci {start_idx}: {ccki_tr[start_idx]} motifs \\nloci {end_idx}: {ccki_tr[end_idx]} motifs \\npartial motif count: {pruned_size} / {len(ccki_tr)}\")\n",
    "    sys.stdout.flush()\n",
    "    start_time = time.time()\n",
    "\n",
    "    # loop through all loci\n",
    "    for i in range(start_idx, end_idx + 1):\n",
    "        curr_m = ccki_tr[i-1] if i != 0 else 0\n",
    "        locus_e = ccki_tr[i] - 1\n",
    "        # loop through all motifs in each loci\n",
    "        while curr_m < locus_e:\n",
    "            # skipped pruned motifs\n",
    "            if not pruned[curr_m - init_locus_start]:\n",
    "                iter_m = curr_m + 1\n",
    "                # comparte current motif with all other motifs in loci\n",
    "                while iter_m <= locus_e:\n",
    "                    # skipped pruned motifs\n",
    "                    if not pruned[iter_m - init_locus_start]:\n",
    "                        r2 = r2_score(acgt[curr_m], acgt[iter_m])\n",
    "                        if r2 > r2_threshold:\n",
    "                            pruned[iter_m - init_locus_start] = True\n",
    "                    iter_m += 1\n",
    "            curr_m += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            compute_time = time.time() - start_time\n",
    "            print(f\"Pruned {i + 1} loci in {compute_time:.2f} seconds\")\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "    # pickle vector of pruned status\n",
    "    print(f\"Dumping pruned...\")\n",
    "    sys.stdout.flush()\n",
    "    with open(f\"{out_dir}/cck_pruned_{r2_threshold}_{start_idx}_{end_idx}.pickle\", 'wb') as f:\n",
    "        pickle.dump(pruned, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return pruned\n",
    "\n",
    "def combine_pruned_files(out_dir, r2_threshold, num_jobs, total_loci):\n",
    "    # Initialize a full pruned array for all loci\n",
    "    pruned_combined = np.zeros(total_loci, dtype=bool)\n",
    "\n",
    "    # Load each pruned pickle file and combine them\n",
    "    for i in range(num_jobs):\n",
    "        start_idx = i * (total_loci // num_jobs)\n",
    "        end_idx = (i + 1) * (total_loci // num_jobs) if i != num_jobs - 1 else total_loci\n",
    "        \n",
    "        with open(f\"{out_dir}/cck_pruned_{r2_threshold}_{start_idx}_{end_idx}.pickle\", 'rb') as f:\n",
    "            pruned_partial = pickle.load(f)\n",
    "        \n",
    "        pruned_combined[start_idx:end_idx] = pruned_partial\n",
    "\n",
    "    # Dump the combined pruned array\n",
    "    with open(f\"{out_dir}/cck_pruned_combined_{r2_threshold}.pickle\", 'wb') as f:\n",
    "        pickle.dump(pruned_combined, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Combined pruned file saved at {out_dir}/cck_pruned_combined_{r2_threshold}.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b090dc66-f1dd-4c75-aac4-ce8594fd0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_1_file=\"/project/mchaisso_100/cmb-17/vntr_genotyping/rpgg2_k21_84k/hprc/full.v1/output8/cdbg/ki_tr.ccki_tr.pickle\"\n",
    "get_2_file=\"/project/mchaisso_100/cmb-17/vntr_genotyping/rpgg2_k21_84k/hprc/full.v1/output8/cdbg/ks.ccks.tr_cck_ns.ki_map.pickle\"\n",
    "gt_HPRC=\"/project/mchaisso_100/cmb-17/vntr_genotyping/aydin/LD_prune/input/genomes.txt\"\n",
    "HPRC_chr1_cov=\"/project/mchaisso_100/cmb-17/vntr_genotyping/aydin/LD_prune/input/1kg_all.cov.tsv\"\n",
    "out=\"/scratch1/tsungyul/aydin/k2m_output\"\n",
    "\n",
    "ki_tr, ccki_tr = get_1(get_1_file)\n",
    "ks, ccks, tr_cck_ns, ki_map = get_2(get_2_file)\n",
    "\n",
    "NK = len(ks)\n",
    "NCCK = len(ccks)\n",
    "NB = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e155bc-fbdb-4a12-90fb-5e16129419a0",
   "metadata": {},
   "source": [
    "# IL dosage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd1e2f2-1242-48d4-a9ac-2ea38980ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acgt = None\n",
    "# if os.path.exists(f\"{out}/acgt.pickle\"):\n",
    "#     print(\"acgt file found\")\n",
    "#     with open(f\"{out}/acgt.pickle\", 'rb') as f:\n",
    "#         acgt =  pickle.load(f)\n",
    "# else:\n",
    "#     print(\"acgt file not found\")\n",
    "#     cgt = gather_motifs(gt_HPRC, NCCK, NB, out)\n",
    "#     acgt =  adjust_coverage(cgt, gt_HPRC, HPRC_chr1_cov, out)\n",
    "\n",
    "# cgt = gather_motifs(gt_HPRC, NCCK, NB, out)\n",
    "# acgt =  adjust_coverage(cgt, gt_HPRC, HPRC_chr1_cov, out)\n",
    "\n",
    "acgt = None\n",
    "if os.path.exists(f\"{out}/acgt.pickle\"):\n",
    "    print(\"acgt file found\")\n",
    "    with open(f\"{out}/acgt.pickle\", 'rb') as f:\n",
    "        acgt =  pickle.load(f)\n",
    "else:\n",
    "    cgt = None\n",
    "    if os.path.exists(f\"{out}/cgt.pickle\"):\n",
    "        print(\"cgt file found\")\n",
    "        with open(f\"{out}/cgt.pickle\", 'rb') as f:\n",
    "            cgt = gather_motifs(gt_HPRC, NCCK, NB, out)\n",
    "    else:\n",
    "        print(\"creating cgt file\")\n",
    "        cgt = gather_motifs(gt_HPRC, NCCK, NB, out)\n",
    "    print(\"creating acgt file\")\n",
    "    acgt =  adjust_coverage(cgt, gt_HPRC, HPRC_chr1_cov, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a83dd6-4cb5-4cad-950e-1656a410c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_threshold = 0.4\n",
    "start_idx = 1\n",
    "end_idx = 3\n",
    "cck_pruned = compute_partial_ld_r2(acgt, ccki_tr, ccks, r2_threshold, out, start_idx, end_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
