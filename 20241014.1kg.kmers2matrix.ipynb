{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "srcdir = \"/project/mchaisso_100/cmb-16/tsungyul/work/vntr/danbing-tk/script/\"\n",
    "sys.path.insert(0, srcdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9faed-6d10-451b-b8fb-ee67737cbae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vntrutils as vu\n",
    "import utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import itertools\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import gzip\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "matplotlib.rc('font', size=7)\n",
    "matplotlib.rc('axes', titlesize=7)\n",
    "matplotlib.rc('xtick', labelsize=5)\n",
    "matplotlib.rc('ytick', labelsize=5)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ffe4bf-9047-4c6a-9f30-34a727d89596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        ki_tr, ccki_tr = pickle.load(f)\n",
    "    return ki_tr, ccki_tr\n",
    "\n",
    "def get_2(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        ks, ccks, tr_cck_ns, ki_map = pickle.load(f)\n",
    "    tr_cck_ns = np.array(tr_cck_ns)\n",
    "    return ks, ccks, tr_cck_ns, ki_map\n",
    "\n",
    "def combine_pruned_files(out_dir, r2_threshold, num_jobs, num_motifs, total_loci, ccki_tr):\n",
    "    loci_per_job = total_loci // num_jobs\n",
    "    pruned_combined = np.zeros(num_motifs, dtype=bool)\n",
    "\n",
    "    # lead each pruned pickle file and combine them\n",
    "    for i in range(num_jobs):\n",
    "        start_loci = i * loci_per_job\n",
    "        end_loci = (i + 1) * loci_per_job - 1 if i != num_jobs - 1 else total_loci - 1\n",
    "        start_motif = ccki_tr[start_loci] if start_loci != 0 else 0\n",
    "        end_motif = ccki_tr[end_loci]\n",
    "        file_path = f\"{out_dir}/cck_pruned_{r2_threshold}_{start_loci}_{end_loci}.pickle\"\n",
    "        # print(f\" Loading {file_path}; motifs {start_motif} to {end_motif}\")\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pruned_partial = pickle.load(f)\n",
    "        \n",
    "        pruned_combined[start_motif:end_motif] = pruned_partial\n",
    "\n",
    "    # dump the combined pruned array\n",
    "    with open(f\"{out_dir}/cck_pruned_combined_{r2_threshold}.pickle\", 'wb') as f:\n",
    "        pickle.dump(pruned_combined, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Combined pruned file saved at {out_dir}/cck_pruned_combined_{r2_threshold}.pickle\")\n",
    "    return pruned_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd1e2f2-1242-48d4-a9ac-2ea38980ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_1_file = \"/project/mchaisso_100/cmb-17/vntr_genotyping/rpgg2_k21_84k/hprc/full.v1/output8/cdbg/ki_tr.ccki_tr.pickle\"\n",
    "get_2_file = \"/project/mchaisso_100/cmb-17/vntr_genotyping/rpgg2_k21_84k/hprc/full.v1/output8/cdbg/ks.ccks.tr_cck_ns.ki_map.pickle\"\n",
    "gt_HPRC = \"/project/mchaisso_100/cmb-17/vntr_genotyping/aydin/LD_prune/input/genomes.txt\"\n",
    "HPRC_chr1_cov = \"/project/mchaisso_100/cmb-17/vntr_genotyping/aydin/LD_prune/input/1kg_all.cov.tsv\"\n",
    "meta = \"/project/mchaisso_100/cmb-17/vntr_genotyping/1kgr/20130606_g1k_3202_samples_ped_population.simple.tsv\"\n",
    "out = \"/scratch1/tsungyul/aydin/k2m_output\"\n",
    "ki_tr, ccki_tr = get_1(get_1_file)\n",
    "ks, ccks, tr_cck_ns, ki_map = get_2(get_2_file)\n",
    "\n",
    "NK = len(ks)\n",
    "NCCK = len(ccks)\n",
    "NB = 40\n",
    "\n",
    "num_jobs = 100\n",
    "total_loci = len(ki_tr)\n",
    "num_motifs = len(ccks)\n",
    "r2_threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da3ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_df = pd.read_csv(meta, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"{out}/acgt.pickle\"):\n",
    "    print(\"acgt file found\")\n",
    "    with open(f\"{out}/acgt.pickle\", 'rb') as f:\n",
    "        acgt =  pickle.load(f)\n",
    "else:\n",
    "    print(\"acgt file NOT found. run job on CARC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a83dd6-4cb5-4cad-950e-1656a410c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{out}/cck_pruned_combined_{r2_threshold}.pickle\"):\n",
    "    print(f\"creating pruned_0_{\".\".split(r2_threshold)[1]}\")\n",
    "    pruned_0_8 = combine_pruned_files(out, 0.8, num_jobs, num_motifs, total_loci, ccki_tr)\n",
    "else:\n",
    "    print(f\"retrieving pruned_0_{\".\".split(r2_threshold)[1]}\")\n",
    "    with open(f\"{out}/cck_pruned_combined_{r2_threshold}.pickle\", 'rb') as f:\n",
    "        pruned_0_8 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune features based on bool vector (keep False)\n",
    "kept_motifs = acgt[~pruned_0_8]\n",
    "\n",
    "# convert pruned features to a df\n",
    "# transpose so each row is a sample and each column is a feature\n",
    "kept_motifs = np.array(kept_motifs).T\n",
    "kept_motifs_df = pd.DataFrame(kept_motifs, columns=[f'feature_{i}' for i in range(kept_motifs.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the sample order matches between kept_motifs_df and df_metadata\n",
    "kept_motifs_df.index = meta_data_df.index\n",
    "\n",
    "# combine metadata and kept features\n",
    "combined_data_df = pd.concat([meta_data_df, kept_motifs_df], axis=1)\n",
    "\n",
    "# set up and run regression tests for each feature\n",
    "population_pvals = []\n",
    "superpopulation_pvals = []\n",
    "for motif in kept_motifs_df.columns:\n",
    "    # TODO: check if col names correct\n",
    "    model_pop = ols(f\"{motif} ~ C(population) + age + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\", \n",
    "                    data = combined_data_df).fit()\n",
    "    population_pvals.append(model_pop.pvalues['C(population)'])\n",
    "\n",
    "    # TODO: check if col names correct\n",
    "    model_superpop = ols(f\"{motif} ~ C(superpopulation) + age + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\", \n",
    "                         data=combined_data_df).fit()\n",
    "    superpopulation_pvals.append(model_superpop.pvalues['C(superpopulation)'])  # Store p-value for superpopulation\n",
    "\n",
    "# apply Benjamini-Hochberg correction for multiple testing\n",
    "population_pvals = np.array(population_pvals)\n",
    "superpopulation_pvals = np.array(superpopulation_pvals)\n",
    "\n",
    "population_significant = multipletests(population_pvals, method='fdr_bh')[0]\n",
    "superpopulation_significant = multipletests(superpopulation_pvals, method='fdr_bh')[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
